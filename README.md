# ğŸš€ Multi-Agent RAG Orchestration (LangChain + LangGraph + DeepAgents + Groq)

This project implements a **production-grade Multi-Agent Retrieval-Augmented Generation (RAG) system** using:

- **LangChain** (loaders, chunking, embeddings, vectorstore, retriever)
- **LangGraph** (graph-based orchestration pattern)
- **DeepAgents**-style multi-agent collaboration
- **Groq LLMs** (ultra-fast open-weight inference)
- **Tenacity-based retry** for rate-limit handling
- **FAISS/Chroma** vectorstore
- **Local PDFs** as the knowledge base

The goal matches the assignment prompt:

> **Build a small Multi-Agent RAG workflow using LangChain, LangGraph, DeepAgents concepts & clean production code, using the provided files as data. Use appropriate chunking and free API providers (Groq).**

This implementation uses **your local PDFs** in `/data` as the knowledge corpus.

---

# ğŸ§  System Architecture

[Architecture diagram included in ChatGPT response above]

---

# ğŸ¤– Agent Roles

### **1. QA Retrieval Agent**
- Retrieves top relevant chunks
- Builds contextual QA prompt
- Queries Groq model (`llama-3.1-8b-instant`)
- Handles rate-limiting via Tenacity
- Produces grounded answers

### **2. Summarizer Agent**
- Uses retrieved chunks to generate summaries
- Provides high-level understanding of context

### **3. Deep Orchestrator**
- Runs agents in **parallel** (async)
- Merges their outputs
- Follows DeepAgents-style design

---

# ğŸ•¸ï¸ LangGraph Flow (Conceptual)

```
Start
 â”‚
 â–¼
RetrieveRelevantChunks
 â”‚
 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â–¼              â–¼
Summarize      AnswerQuestion
 â”‚              â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â–¼
      MergeNodes
         â–¼
        End
```

---

# ğŸ“‚ File Structure

```
multi-agent-rag/
â”œâ”€â”€ data/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ qa_agent.py
â”‚   â”‚   â””â”€â”€ summarizer.py
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ langgraph.yaml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

# ğŸ“¦ Chunking Methodology

- Recursive character text splitting  
- Chunk size: **1000**, overlap: **200**  
- Ensures semantic continuity and high recall retrieval

---

# âš¡ Groq Model (Free Tier)

Uses:
- `llama-3.1-8b-instant`  
- Groq's OpenAI-compatible endpoint  
- Tenacity retry handling  

---

# ğŸ› ï¸ Setup

```
git clone https://github.com/pallavikailas/multi-agent-rag.git
cd multi-agent-rag
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
nano .env
```

Add your `GROQ_API_KEY=gsk_xxxxxx`

---

# â–¶ï¸ Run the Pipeline

```
./.venv/bin/python -m src.main
```

---

# ğŸ³ Docker

```
docker-compose build
docker-compose up
```

---

# âœ”ï¸ Assignment Checklist

| Requirement | Status |
|------------|--------|
| Multi-agent system | âœ… |
| LangChain | âœ… |
| LangGraph concepts | âœ“ Graph design + flow |
| DeepAgents design | âœ… |
| Chunking | Recursive splitter |
| Use provided files | Yes |
| Free API (Groq) | Yes |
| Rate limit handling | Tenacity |

---
